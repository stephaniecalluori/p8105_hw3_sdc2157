---
title: "p8105_hw3_sdc2157"
author: "Stephanie Calluori"
date: 2023-10-14
output: github_document
---

# Load packages

```{r, load packages, message = FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(ggridges)

```

# Data Import

```{r, data import, results = FALSE, message = FALSE}
data("instacart")

data("brfss_smart2010")

demographic_raw <- read_csv("data/nhanes_covar.csv", skip = 4, col_names = TRUE)
head(demographic_raw)
tail(demographic_raw)
colnames(demographic_raw)

accel_raw <- read_csv("data/nhanes_accel.csv", col_names = TRUE)
head(accel_raw)
tail(accel_raw)
colnames(accel_raw)

```

```{r, setup, echo = FALSE, results = FALSE, message = FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "right"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

# Problem 1

```{r, clean and summarize instacart}
instacart_clean <- instacart |> 
  janitor::clean_names()

na_num <- sum(is.na(instacart_clean))

popular_items <- instacart_clean |> 
  group_by(product_name) |> 
  summarize(product_n = n()) |> 
  arrange(desc(product_n))

```

The instacart data set contains `r nrow(instacart_clean)` observations and `r ncol(instacart_clean)` variables. Each observation corresponds to a product from an order. There are `r instacart_clean |> distinct(order_id) |> nrow()` orders from `r instacart_clean |> distinct(user_id) |> nrow()` users (i.e., one order per user). 

Variables include `r colnames(instacart_clean)`. All variables are integers except for 4 character variables. NA values are not present in the data set. 

Across the orders, a total of `r instacart_clean |> distinct(product_id) |> nrow()` distinct products were purchased. The most purchased item was `r popular_items[1,1]`. 

```{r, aisle summaries}
num_aisle <- instacart_clean |> 
  count(aisle_id) |> 
  nrow()

aisle_items <- instacart_clean |> 
  group_by(aisle) |> 
  summarize(n_items = n()) |> 
  arrange(desc(n_items))

```

Customers ordered from `r num_aisle` different aisles. The top 3 aisles from which the most items are ordered are `r aisle_items[1,1]`, `r aisle_items[2,1]`, and `r aisle_items[3,1]`.

```{r, aisle plot}
aisle_items |> 
  filter(n_items > 10000) |> 
  mutate(aisle = forcats::fct_reorder(aisle, n_items, .desc = TRUE)) |> 
  ggplot(aes(x = aisle, y = n_items)) +
  geom_col() +
  labs(
    title = "Number of items ordered from each aisle",
    x = "Aisle",
    y = "Number of items",
    caption = "*Only includes aisles from which >10,000 items were ordered"
  ) +
  theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))

```

Following the top 3 aisles, yogurt, packaged cheese, and walter seltzer sparkling water were the most popular aisles.


```{r, aisle table}
instacart_clean |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  group_by(aisle, product_name) |> 
  summarize(times_ordered = n()) |> 
  arrange(desc(times_ordered)) |> 
  mutate(rank = min_rank(desc(times_ordered))) |>
  filter(rank < 4) |> 
  knitr::kable(digits = 2)
  
```

The top item ordered in the packaged vegetables fruits aisle was organic baby spinach. In the baking ingredients aisle, light brown sugar was the most ordered item. Small dog biscuits was the top item ordered in the dog food care aisle.


```{r, order time table}
instacart_clean |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> 
  mutate(
    order_dow = recode(
      order_dow, 
      "0" = "Sunday",
      "1" = "Monday",
      "2" = "Tuesday",
      "3" = "Wednesday",
      "4" = "Thursday",
      "5" = "Friday",
      "6" = "Saturday"),
  ) |> 
  group_by(product_name, order_dow) |> 
  arrange(product_name) |> 
  summarize(avg_hr = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = avg_hr
  ) |>   
  select(product_name, Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday) |> 
  knitr::kable(digits = 2)

```

The table above shows the mean hour of the day at which Coffee Ice Cream and Pink Lady Apples were ordered on each day of the week. Overall, these items were typically ordered between late morning and mid-afternoon, regardless of the day of the week.


# Problem 2
50 states and Washington DC
```{r}
brfss_clean <- brfss_smart2010 |> 
  janitor::clean_names() |> 
  rename(state = locationabbr, county = locationdesc) |> 
  filter(topic == "Overall Health", 
         response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |> 
  mutate(response = fct_relevel(response, 
                                c("Poor", "Fair", "Good", "Very good", "Excellent")))

unique(brfss_clean$state)

```

In 2002, which states were observed at 7 or more locations? 

```{r}
brfss_clean |> 
  select(year, state, county) |> 
  filter(year == "2002") |> 
  group_by(state) |> 
  distinct(county) |>
  summarize(num_county = n()) |> 
  filter(num_county >= 7) |> 
  arrange(desc(num_county)) |> 
  knitr::kable(digits = 2)

```


In 2010, which states were observed at 7 or more locations?

```{r}
brfss_clean |> 
  select(year, state, county) |> 
  filter(year == "2010") |> 
  group_by(state) |>
  distinct(county) |> 
  summarize(num_county = n()) |> 
  filter(num_county >= 7) |> 
  arrange(desc(num_county)) |> 
  knitr::kable(digits = 2)

```

Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).

###Office Hrs ASK ABOUT: strategies to make more readable, check on group aesthetic?

```{r}
brfss_clean |> 
  select(year, state, county, response, data_value) |>
  drop_na() |> 
  filter(response == "Excellent") |> 
  group_by(state, year) |> 
  summarize(avg_data_value = mean(data_value)) |> 
  ggplot(aes(x = year, y = avg_data_value, color = state)) +
  geom_line() 
  
```

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
brfss_clean |> 
  select(year, state, response, data_value) |> 
  filter(year %in% c(2006, 2010), state == "NY") |> 
  mutate(response = fct_reorder(response, data_value)) |> 
  ggplot(aes(x = data_value, y = response)) +
  geom_density_ridges() +
  facet_grid(.~year)
```

#Problem 3
Load, tidy, merge, and otherwise organize the data sets. Your final dataset should include all originally observed variables; exclude participants less than 21 years of age, and those with missing demographic data; and encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).

```{r}
demographic_clean <- demographic_raw |> 
  janitor::clean_names() |> 
  mutate(sex = as.factor(sex),
         education = as.factor(education)
         ) |>
  mutate(sex = recode(sex, 
                      "1" = "male", 
                      "2" = "female"),
         education = recode(education, 
             "1" = "Less than high school",
             "2" = "High school equivalent",
             "3" = "More than high school")) |> 
  drop_na() |> 
  filter(age >= 21)

nrow(demographic_clean)

accel_clean <- accel_raw |> 
  janitor::clean_names()

combined_accel <- left_join(demographic_clean, accel_clean, by = "seqn")
nrow(combined_accel)
head(combined_accel)
  
```



Produce a reader-friendly table for the number of men and women in each education category

```{r}
combined_accel |> 
  group_by(education, sex) |> 
  summarize(n_obs = n()) |> 
  pivot_wider(
    names_from = sex,
    values_from = n_obs,
  ) |> 
  knitr::kable(digits = 2)

```

create a visualization of the age distributions for men and women in each education category.

```{r}
combined_accel |> 
  ggplot(aes(x = age, y = sex)) +
  geom_density_ridges() +
  facet_grid(. ~ education)

combined_accel |> 
  ggplot(aes(x = age, y = sex)) +
  geom_density_ridges() +
  facet_grid(education ~ .)

```

```{r}
combined_accel |> 
  ggplot(aes(x = sex, y = age)) +
  geom_boxplot() +
  facet_grid(. ~ education)
```

Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. 

```{r}
tail(colnames(combined_accel))

combined_accel |>
  mutate(total_activity = rowSums(across(min1:min1440))) |> 
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point() +
  geom_smooth(se=FALSE) +
  facet_grid(education ~ .)


```
Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

when you group by seqn it calculate averages mims for each minute
need to convert minute to numeric so you get continous x axis
```{r}
colnames(combined_accel)
str(combined_accel)
combined_accel |> 
  pivot_longer(
    min1:min1440,
    names_to = "minute",
    names_prefix = "min",
    values_to = "mims"
  ) |> 
  mutate(minute = as.numeric(minute)) |> 
  ggplot(aes(x = minute, y = mims, group = seqn, color = sex)) +
  geom_line() +
  geom_smooth(aes(group = sex)) +
  facet_grid(. ~ education)

```


try using boxplots!!!!

