p8105_hw3_sdc2157
================
Stephanie Calluori
2023-10-14

``` r
library(tidyverse)
library(p8105.datasets)

data("instacart")

data("brfss_smart2010")

demographic_raw <- read_csv("data/nhanes_covar.csv", skip = 4, col_names = TRUE)
head(demographic_raw)
tail(demographic_raw)
colnames(demographic_raw)

accel_raw <- read_csv("data/nhanes_accel.csv", col_names = TRUE)
head(accel_raw)
tail(accel_raw)
colnames(accel_raw)
```

# Problem 1

``` r
instacart_clean <- instacart |> 
  janitor::clean_names()

head(instacart_clean)
```

    ## # A tibble: 6 × 15
    ##   order_id product_id add_to_cart_order reordered user_id eval_set order_number
    ##      <int>      <int>             <int>     <int>   <int> <chr>           <int>
    ## 1        1      49302                 1         1  112108 train               4
    ## 2        1      11109                 2         1  112108 train               4
    ## 3        1      10246                 3         0  112108 train               4
    ## 4        1      49683                 4         0  112108 train               4
    ## 5        1      43633                 5         1  112108 train               4
    ## 6        1      13176                 6         0  112108 train               4
    ## # ℹ 8 more variables: order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

``` r
str(instacart_clean)
```

    ## tibble [1,384,617 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ order_id              : int [1:1384617] 1 1 1 1 1 1 1 1 36 36 ...
    ##  $ product_id            : int [1:1384617] 49302 11109 10246 49683 43633 13176 47209 22035 39612 19660 ...
    ##  $ add_to_cart_order     : int [1:1384617] 1 2 3 4 5 6 7 8 1 2 ...
    ##  $ reordered             : int [1:1384617] 1 1 0 0 1 0 0 1 0 1 ...
    ##  $ user_id               : int [1:1384617] 112108 112108 112108 112108 112108 112108 112108 112108 79431 79431 ...
    ##  $ eval_set              : chr [1:1384617] "train" "train" "train" "train" ...
    ##  $ order_number          : int [1:1384617] 4 4 4 4 4 4 4 4 23 23 ...
    ##  $ order_dow             : int [1:1384617] 4 4 4 4 4 4 4 4 6 6 ...
    ##  $ order_hour_of_day     : int [1:1384617] 10 10 10 10 10 10 10 10 18 18 ...
    ##  $ days_since_prior_order: int [1:1384617] 9 9 9 9 9 9 9 9 30 30 ...
    ##  $ product_name          : chr [1:1384617] "Bulgarian Yogurt" "Organic 4% Milk Fat Whole Milk Cottage Cheese" "Organic Celery Hearts" "Cucumber Kirby" ...
    ##  $ aisle_id              : int [1:1384617] 120 108 83 83 95 24 24 21 2 115 ...
    ##  $ department_id         : int [1:1384617] 16 16 4 4 15 4 4 16 16 7 ...
    ##  $ aisle                 : chr [1:1384617] "yogurt" "other creams cheeses" "fresh vegetables" "fresh vegetables" ...
    ##  $ department            : chr [1:1384617] "dairy eggs" "dairy eggs" "produce" "produce" ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   order_id = col_integer(),
    ##   ..   product_id = col_integer(),
    ##   ..   add_to_cart_order = col_integer(),
    ##   ..   reordered = col_integer(),
    ##   ..   user_id = col_integer(),
    ##   ..   eval_set = col_character(),
    ##   ..   order_number = col_integer(),
    ##   ..   order_dow = col_integer(),
    ##   ..   order_hour_of_day = col_integer(),
    ##   ..   days_since_prior_order = col_integer(),
    ##   ..   product_name = col_character(),
    ##   ..   aisle_id = col_integer(),
    ##   ..   department_id = col_integer(),
    ##   ..   aisle = col_character(),
    ##   ..   department = col_character()
    ##   .. )

``` r
sum(is.na(instacart_clean))
```

    ## [1] 0

``` r
num_users <- instacart_clean |> 
  distinct(user_id)
```

The data set describes

The data set contains 1384617 observations and 15. Each observation
corresponds to a distinct instacart product. Variables include order_id,
product_id, add_to_cart_order, reordered, user_id, eval_set,
order_number, order_dow, order_hour_of_day, days_since_prior_order,
product_name, aisle_id, department_id, aisle, department.

``` r
num_aisle <- instacart_clean |> 
  count(aisle_id) |> 
  nrow()

aisle_items <- instacart_clean |> 
  select(aisle, product_name) |> 
  group_by(aisle) |> 
  summarize(
    n_items = n()
  ) |> 
  arrange(desc(n_items))
```

fresh veggies, fresh fruits, and packaged vegtables/fruits

``` r
plot <- aisle_items |> 
  filter(n_items > 10000) |> 
  ggplot(aes(x = aisle, y = n_items)) +
  geom_col()
```

Make a plot that shows the number of items ordered in each aisle,
limiting this to aisles with more than 10000 items ordered. Arrange
aisles sensibly, and organize your plot so others can read it.

``` r
pop_items <- instacart_clean |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  group_by(aisle, product_name) |> 
  summarize(n_obs = n()) |> 
  arrange(desc(n_obs)) |> 
  mutate(rank = min_rank(desc(n_obs))) |>
  filter(rank < 4) |> 
  knitr::kable(digits = 2)
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the
    ## `.groups` argument.

Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
Include the number of times each item is ordered in your table.

``` r
sub <- instacart_clean |> 
  drop_na() |> 
  select(product_name, order_dow, order_hour_of_day) |> 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> 
  mutate(
    order_dow = recode(
      order_dow, 
      "0" = "Sunday",
      "1" = "Monday",
      "2" = "Tuesday",
      "3" = "Wednesday",
      "4" = "Thursday",
      "5" = "Friday",
      "6" = "Saturday"),
  ) |> 
  group_by(product_name, order_dow) |> 
  arrange(product_name) |> 
  summarize(avg_hr = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = avg_hr
  )
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

# Problem 2

50 states and Washington DC

``` r
brfss_clean <- brfss_smart2010 |> 
  janitor::clean_names() |> 
  rename(state = locationabbr, county = locationdesc) |> 
  filter(topic == "Overall Health", 
         response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |> 
  mutate(response = fct_relevel(response, 
                                c("Poor", "Fair", "Good", "Very good", "Excellent")))

unique(brfss_clean$state)
```

    ##  [1] "AL" "AZ" "AR" "CA" "CO" "CT" "DE" "DC" "FL" "GA" "HI" "ID" "IL" "IN" "IA"
    ## [16] "KS" "LA" "KY" "ME" "MD" "MA" "MI" "MN" "MO" "MS" "MT" "NE" "NV" "NH" "NJ"
    ## [31] "NM" "NY" "NC" "ND" "OH" "OK" "OR" "PA" "RI" "SC" "SD" "TN" "TX" "UT" "VT"
    ## [46] "WA" "WI" "WV" "WY" "AK" "VA"

In 2002, which states were observed at 7 or more locations?

``` r
brfss_clean |> 
  select(year, state, county) |> 
  filter(year == "2002") |> 
  group_by(state) |> 
  distinct(county) |>
  summarize(num_county = n()) |> 
  filter(num_county >= 7) |> 
  arrange(desc(num_county)) |> 
  knitr::kable(digits = 2)
```

| state | num_county |
|:------|-----------:|
| PA    |         10 |
| MA    |          8 |
| NJ    |          8 |
| CT    |          7 |
| FL    |          7 |
| NC    |          7 |

In 2010, which states were observed at 7 or more locations?

``` r
brfss_clean |> 
  select(year, state, county) |> 
  filter(year == "2010") |> 
  group_by(state) |>
  distinct(county) |> 
  summarize(num_county = n()) |> 
  filter(num_county >= 7) |> 
  arrange(desc(num_county)) |> 
  knitr::kable(digits = 2)
```

| state | num_county |
|:------|-----------:|
| FL    |         41 |
| NJ    |         19 |
| TX    |         16 |
| CA    |         12 |
| MD    |         12 |
| NC    |         12 |
| NE    |         10 |
| WA    |         10 |
| MA    |          9 |
| NY    |          9 |
| OH    |          8 |
| CO    |          7 |
| PA    |          7 |
| SC    |          7 |

``` r
str(brfss_clean)
```

    ## tibble [10,625 × 23] (S3: tbl_df/tbl/data.frame)
    ##  $ year                      : int [1:10625] 2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ...
    ##  $ state                     : chr [1:10625] "AL" "AL" "AL" "AL" ...
    ##  $ county                    : chr [1:10625] "AL - Jefferson County" "AL - Jefferson County" "AL - Jefferson County" "AL - Jefferson County" ...
    ##  $ class                     : chr [1:10625] "Health Status" "Health Status" "Health Status" "Health Status" ...
    ##  $ topic                     : chr [1:10625] "Overall Health" "Overall Health" "Overall Health" "Overall Health" ...
    ##  $ question                  : chr [1:10625] "How is your general health?" "How is your general health?" "How is your general health?" "How is your general health?" ...
    ##  $ response                  : Factor w/ 5 levels "Poor","Fair",..: 5 4 3 2 1 5 4 3 2 1 ...
    ##  $ sample_size               : int [1:10625] 94 148 208 107 45 91 177 224 120 66 ...
    ##  $ data_value                : num [1:10625] 18.9 30 33.1 12.5 5.5 15.6 31.3 31.2 15.5 6.4 ...
    ##  $ confidence_limit_low      : num [1:10625] 14.1 24.9 28.2 9.5 3.5 11 26 26.1 11.7 4.4 ...
    ##  $ confidence_limit_high     : num [1:10625] 23.6 35 38 15.4 7.4 20.1 36.5 36.2 19.2 8.3 ...
    ##  $ display_order             : int [1:10625] 1 2 3 4 5 1 2 3 4 5 ...
    ##  $ data_value_unit           : chr [1:10625] "%" "%" "%" "%" ...
    ##  $ data_value_type           : chr [1:10625] "Crude Prevalence" "Crude Prevalence" "Crude Prevalence" "Crude Prevalence" ...
    ##  $ data_value_footnote_symbol: chr [1:10625] NA NA NA NA ...
    ##  $ data_value_footnote       : chr [1:10625] NA NA NA NA ...
    ##  $ data_source               : chr [1:10625] "BRFSS" "BRFSS" "BRFSS" "BRFSS" ...
    ##  $ class_id                  : chr [1:10625] "CLASS08" "CLASS08" "CLASS08" "CLASS08" ...
    ##  $ topic_id                  : chr [1:10625] "Topic41" "Topic41" "Topic41" "Topic41" ...
    ##  $ location_id               : chr [1:10625] NA NA NA NA ...
    ##  $ question_id               : chr [1:10625] "GENHLTH" "GENHLTH" "GENHLTH" "GENHLTH" ...
    ##  $ respid                    : chr [1:10625] "RESP056" "RESP057" "RESP058" "RESP059" ...
    ##  $ geo_location              : chr [1:10625] "(33.518601, -86.814688)" "(33.518601, -86.814688)" "(33.518601, -86.814688)" "(33.518601, -86.814688)" ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   Year = col_integer(),
    ##   ..   Locationabbr = col_character(),
    ##   ..   Locationdesc = col_character(),
    ##   ..   Class = col_character(),
    ##   ..   Topic = col_character(),
    ##   ..   Question = col_character(),
    ##   ..   Response = col_character(),
    ##   ..   Sample_Size = col_integer(),
    ##   ..   Data_value = col_double(),
    ##   ..   Confidence_limit_Low = col_double(),
    ##   ..   Confidence_limit_High = col_double(),
    ##   ..   Display_order = col_integer(),
    ##   ..   Data_value_unit = col_character(),
    ##   ..   Data_value_type = col_character(),
    ##   ..   Data_Value_Footnote_Symbol = col_character(),
    ##   ..   Data_Value_Footnote = col_character(),
    ##   ..   DataSource = col_character(),
    ##   ..   ClassId = col_character(),
    ##   ..   TopicId = col_character(),
    ##   ..   LocationID = col_character(),
    ##   ..   QuestionID = col_character(),
    ##   ..   RESPID = col_character(),
    ##   ..   GeoLocation = col_character()
    ##   .. )

Construct a dataset that is limited to Excellent responses, and
contains, year, state, and a variable that averages the data_value
across locations within a state. Make a “spaghetti” plot of this average
value over time within a state (that is, make a plot showing a line for
each state across years – the geom_line geometry and group aesthetic
will help).

``` r
brfss_clean |> 
  select(year, state, county, response, data_value) |>
  drop_na() |> 
  filter(response == "Excellent") |> 
  group_by(state, year) |> 
  summarize(avg_data_value = mean(data_value)) |> 
  ggplot(aes(x = year, y = avg_data_value, color = state)) +
  geom_line() 
```

    ## `summarise()` has grouped output by 'state'. You can override using the
    ## `.groups` argument.

<img src="p8105_hw3_sdc2157_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

Make a two-panel plot showing, for the years 2006, and 2010,
distribution of data_value for responses (“Poor” to “Excellent”) among
locations in NY State.
